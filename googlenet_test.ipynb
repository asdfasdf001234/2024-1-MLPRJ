{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+xOxunmR+5lnBUKP27Ph9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asdfasdf001234/2024-1-MLPRJ/blob/main/googlenet_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oLHZr9I8YEEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d2b8b7-7600-409a-9717-0092b2eef9d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import pandas as pd\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "P96SZNjSmfp7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a93NbVEeNbiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/24-1 기계학습 팀프로젝트/img_model_test'"
      ],
      "metadata": {
        "id": "O8tDS6Ddmhnv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "jOFa5foKm8Gp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframe(data_path, label_list):\n",
        "    df = pd.DataFrame(columns=[\"path\", \"label\", \"class_id\"])\n",
        "    img_list = glob(os.path.join(data_path, '*.jpg'))\n",
        "\n",
        "    for img in img_list:\n",
        "        file_name = os.path.splitext(os.path.basename(img))[0]\n",
        "        label_index = int(file_name[0]) - 1  # 파일 이름의 첫 번째 문자를 int로 변환하여 라벨 인덱스를 결정\n",
        "        if 0 <= label_index < len(label_list):\n",
        "            label = label_list[label_index]\n",
        "            new_data = pd.DataFrame({\"path\": [img], \"label\": [label], \"class_id\": [label_index]})\n",
        "            df = pd.concat([df, new_data], ignore_index=True)\n",
        "\n",
        "    df[\"path\"] = df[\"path\"].astype(str)\n",
        "    df[\"label\"] = df[\"label\"].astype(str)\n",
        "    df[\"class_id\"] = df[\"class_id\"].astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "data_path = \"/path_to_your_data_directory\"\n",
        "train_path = os.path.join(data_path, 'Training')\n",
        "valid_path = os.path.join(data_path, 'Validation')\n",
        "test_path = os.path.join(data_path, 'Testing')\n",
        "label_list = ['spring', 'summer', 'fall', 'winter']\n",
        "\n",
        "train_df = create_dataframe(train_path, label_list)\n",
        "val_df = create_dataframe(valid_path, label_list)\n",
        "test_df = create_dataframe(test_path, label_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "AiMPWS-W2zh7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터로더\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['test', 'train', 'val']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "class_names = image_datasets['train'].classes"
      ],
      "metadata": {
        "id": "8PDvHF6ExhjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ba86b8-1c6d-4ec7-a462-5f937777b3c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#장치 설정 - GPU or CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "0se42VXbxxVp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#구글넷 모델을 불러오기\n",
        "model = models.googlenet(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  # 4개의 퍼스널 컬러 클래스\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "L5z98AYWx5qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983da9c7-6eaf-4b44-9949-86077d91565b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss 및 optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "ZHZt-c2UyU7m"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "PpNgewqLyec0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RT7phnXJ1QGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "model = train_model(model, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), 'personal_color_googlenet.pth')\n",
        "\n",
        "# 테스트 데이터로 모델 평가\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_corrects = 0\n",
        "\n",
        "for inputs, labels in dataloaders['test']:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "    test_loss += loss.item() * inputs.size(0)\n",
        "    test_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "test_loss = test_loss / dataset_sizes['test']\n",
        "test_acc = test_corrects.double() / dataset_sizes['test']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvCiVPg2yhgM",
        "outputId": "a419b16a-dbae-4c19-a736-efaccfa12e81"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 0.6494 Acc: 0.8250\n",
            "val Loss: 0.1122 Acc: 1.0000\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.0177 Acc: 1.0000\n",
            "val Loss: 0.0064 Acc: 1.0000\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 0.0025 Acc: 1.0000\n",
            "val Loss: 0.0021 Acc: 1.0000\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 0.0013 Acc: 1.0000\n",
            "val Loss: 0.0014 Acc: 1.0000\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.0009 Acc: 1.0000\n",
            "val Loss: 0.0011 Acc: 1.0000\n",
            "\n",
            "Best val Acc: 1.000000\n",
            "Test Loss: 0.1172 Acc: 1.0000\n"
          ]
        }
      ]
    }
  ]
}