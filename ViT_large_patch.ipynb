{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4151da85aac14f7fa868e2fb58229738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03e64467bc514194b43103ec23d9512c",
              "IPY_MODEL_951cf22cb6b1435fa8166ee33f336964",
              "IPY_MODEL_8e96f8a871f24732856dcf41d87a40e0"
            ],
            "layout": "IPY_MODEL_c5a458eb7e444108b1b06ca4ec699bd8"
          }
        },
        "03e64467bc514194b43103ec23d9512c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_883e452a44b140b5b6784e20fe46fe6c",
            "placeholder": "​",
            "style": "IPY_MODEL_4efa068857364de2bd1216836aa5b59e",
            "value": "model.safetensors: 100%"
          }
        },
        "951cf22cb6b1435fa8166ee33f336964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce372f7d31c48999d7d8200f26d52d8",
            "max": 1217502758,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79665c7caf8246dc803489c0151e9afd",
            "value": 1217502758
          }
        },
        "8e96f8a871f24732856dcf41d87a40e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31b328b84afb4f2189d12585fc01b18d",
            "placeholder": "​",
            "style": "IPY_MODEL_1c0495739c5844deb923cc4f22e0d4ef",
            "value": " 1.22G/1.22G [00:16&lt;00:00, 81.8MB/s]"
          }
        },
        "c5a458eb7e444108b1b06ca4ec699bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883e452a44b140b5b6784e20fe46fe6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4efa068857364de2bd1216836aa5b59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bce372f7d31c48999d7d8200f26d52d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79665c7caf8246dc803489c0151e9afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31b328b84afb4f2189d12585fc01b18d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0495739c5844deb923cc4f22e0d4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asdfasdf001234/2024-1-MLPRJ/blob/main/ViT_large_patch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF5xQGj9DqXx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import seaborn as sns\n",
        "\n",
        "# pretrained 관련\n",
        "import torch\n",
        "import torchvision.transforms as v2\n",
        "from torchvision import models\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_random_seed(seed_value):\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    random.seed(seed_value)\n",
        "\n",
        "# Set a random seed value\n",
        "seed_value = 42\n",
        "set_random_seed(seed_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZo2AcfiTyTO",
        "outputId": "d52bb6e9-66ed-4512-d68c-1638652ff37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset , DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "data_dir = \"/content/drive/MyDrive/Data\""
      ],
      "metadata": {
        "id": "E-DkVabbD4EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "def create_dataframe(data_path, label_list, data_type):\n",
        "    df = pd.DataFrame({\"path\": [], \"label\": [], \"class_id\": []})\n",
        "    img_list = glob(os.path.join(data_path, '*.jpg'))\n",
        "\n",
        "    for img in img_list:\n",
        "      file_name = os.path.splitext(os.path.basename(img))[0]\n",
        "      label_index = int(file_name[0]) - 1\n",
        "      if label_index == 0 or label_index == 2:   #웜톤\n",
        "        label_index = 0                          #0으로 통일\n",
        "      else:                                      #쿨톤\n",
        "        label_index = 1                          #1으로 통일\n",
        "      if 0 <= label_index < len(label_list):\n",
        "        label = label_list[label_index]\n",
        "        new_data = pd.DataFrame({\"path\": [img], \"label\": [label], \"class_id\": [label_index]})\n",
        "        df = pd.concat([df, new_data], ignore_index=True)\n",
        "\n",
        "\n",
        "    df[[\"path\"]] = df[[\"path\"]].astype(str)\n",
        "    df[[\"label\"]] = df[[\"label\"]].astype(str)\n",
        "    df[[\"class_id\"]] = df[[\"class_id\"]].astype(int)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "emQocv1ZD9Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 example 코드\n",
        "train_path = data_dir + '/train'\n",
        "valid_path = data_dir + '/val'\n",
        "test_path = data_dir + '/test'\n",
        "label_list = ['warm', 'cool']\n",
        "\n",
        "train_df = create_dataframe(train_path, label_list, 'training')\n",
        "val_df = create_dataframe(valid_path, label_list, 'validation')\n",
        "test_df = create_dataframe(test_path, label_list, 'testing')"
      ],
      "metadata": {
        "id": "wA3_8kmIECKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_data: {len(train_df)}\")\n",
        "print(f\"val_data:{len(val_df)}\")\n",
        "print(f\"test_data:{len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WniOgg3IEEQn",
        "outputId": "4b4f38ee-63c2-4c22-9904-b66ce76816f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data: 446\n",
            "val_data:137\n",
            "test_data:104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self , dataframe , transforms_):\n",
        "        self.df = dataframe\n",
        "        self.transforms_ = transforms_\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self ,index):\n",
        "        img_path = self.df.iloc[index]['path']\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        transformed_img = self.transforms_(img)\n",
        "        class_id = self.df.iloc[index]['class_id']\n",
        "        return transformed_img , class_id"
      ],
      "metadata": {
        "id": "8WCdOeRjEIpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transforms = v2.Compose([\n",
        "    v2.RandomRotation(degrees=10),\n",
        "    v2.RandomHorizontalFlip(p=0.8),\n",
        "    #v2.ScaleJitter(target_size=(224,224)),\n",
        "    v2.RandomAffine(degrees=45),\n",
        "    #v2.ColorJitter(0.5, 0.5),\n",
        "    #v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
        "\n",
        "    v2.Resize((224,224)), #사이즈를 64*64\n",
        "    v2.PILToTensor(),\n",
        "    v2.ToDtype(torch.float32),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])"
      ],
      "metadata": {
        "id": "gMImJBQJEJ3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 30\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "_YGRg4lwELQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get dataloader\n",
        "\n",
        "train_dataset = BaseDataset(train_df, Transforms) # train_transforms\n",
        "val_dataset = BaseDataset(val_df, Transforms)\n",
        "test_dataset = BaseDataset(test_df, Transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset , batch_size=BATCH_SIZE , shuffle = True)\n",
        "val_loader = DataLoader(val_dataset , batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset , batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "vzKmNyXgENj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "bZbbGiVTYuHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcddd41-1e04-4205-8525-cfd785590533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->timm)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 timm-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VIT 모델\n",
        "import timm\n",
        "model = timm.create_model('timm/vit_large_patch14_dinov2.lvd142m', pretrained=True, num_classes=0, img_size=[224,224])"
      ],
      "metadata": {
        "id": "pBO5pU8QYHsJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4151da85aac14f7fa868e2fb58229738",
            "03e64467bc514194b43103ec23d9512c",
            "951cf22cb6b1435fa8166ee33f336964",
            "8e96f8a871f24732856dcf41d87a40e0",
            "c5a458eb7e444108b1b06ca4ec699bd8",
            "883e452a44b140b5b6784e20fe46fe6c",
            "4efa068857364de2bd1216836aa5b59e",
            "bce372f7d31c48999d7d8200f26d52d8",
            "79665c7caf8246dc803489c0151e9afd",
            "31b328b84afb4f2189d12585fc01b18d",
            "1c0495739c5844deb923cc4f22e0d4ef"
          ]
        },
        "outputId": "4badcf74-f159-48d9-d9c3-25a33fff4339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4151da85aac14f7fa868e2fb58229738"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7YCY_AxYdYH",
        "outputId": "d40a7816-0017-4d0a-f928-8dc61a338acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VisionTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
            "    (norm): Identity()\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (patch_drop): Identity()\n",
            "  (norm_pre): Identity()\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (1): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (2): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (3): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (4): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (5): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (6): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (7): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (8): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (9): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (10): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (11): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (12): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (13): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (14): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (15): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (16): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (17): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (18): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (19): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (20): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (21): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (22): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (23): Block(\n",
            "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): LayerScale()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): LayerScale()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "  (fc_norm): Identity()\n",
            "  (head_drop): Dropout(p=0.0, inplace=False)\n",
            "  (head): Identity()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새 분류 레이어 추가 (4개의 클래스)\n",
        "class CustomVitModel(nn.Module):\n",
        "    def __init__(self, base_model, num_classes):\n",
        "        super(CustomVitModel, self).__init__()\n",
        "        self.base_model = base_model #backbone이 아닌 basemodel\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        #파라미터 고정(frozen)\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        for name, param in self.base_model.named_parameters():\n",
        "          if 'fc1' in name or 'fc2' in name or 'classifier' in name:\n",
        "            param.requires_grad = True\n",
        "          else:\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # 원래 모델의 출력 특성 차원을 가져옴\n",
        "        in_features = base_model.num_features\n",
        "\n",
        "        # 새로운 분류 레이어 정의\n",
        "        #self.classifier = nn.Linear(in_features, num_classes)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512,256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 원래 모델의 출력 특징 추출\n",
        "        features = self.base_model(x)\n",
        "\n",
        "        # 새로운 분류 레이어를 통과시켜 최종 출력\n",
        "        out = self.classifier(features)\n",
        "        return out\n",
        "\n",
        "# 새 모델 정의 (4개의 클래스로 분류)\n",
        "num_classes = 2\n",
        "large_vit_model = CustomVitModel(model, num_classes)\n",
        "\n",
        "# 모델 구조 확인\n",
        "print(large_vit_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qYD2yO2apBS",
        "outputId": "a95bc49b-b925-4af4-a336-5e892866d71c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomVitModel(\n",
            "  (base_model): VisionTransformer(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "    (patch_drop): Identity()\n",
            "    (norm_pre): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (9): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (10): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (11): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (12): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (13): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (14): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (15): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (16): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (17): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (18): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (19): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (20): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (21): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (22): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (23): Block(\n",
            "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): LayerScale()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): LayerScale()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "    (fc_norm): Identity()\n",
            "    (head_drop): Dropout(p=0.0, inplace=False)\n",
            "    (head): Identity()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader , model , loss_fn , optimizer , lr_scheduler=None):\n",
        "    size = 0\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss , epoch_correct = 0 , 0\n",
        "\n",
        "    for i ,(data_ , target_) in enumerate(dataloader):\n",
        "        #===================================================#\n",
        "        #모델 예측값과 실제 값\n",
        "        data_, target_ = data_.to(device), target_.to(device)\n",
        "        size += data_.size(0)\n",
        "\n",
        "        pred = model(data_)\n",
        "        _, pread_max = torch.max(pred,1)\n",
        "        loss = loss_fn(pred, target_)\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_correct += (  pread_max == target_ ).type(torch.float).sum().item()\n",
        "\n",
        "        #역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        #===================================================#\n",
        "\n",
        "    if lr_scheduler != None:\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    return epoch_correct/size , epoch_loss / num_batches"
      ],
      "metadata": {
        "id": "z_ryDQiHUmAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader , model , loss_fn):\n",
        "    size = 0\n",
        "    num_baches = len(dataloader)\n",
        "    epoch_loss , epoch_correct= 0 ,0\n",
        "\n",
        "    with torch.no_grad(): # grad 연산 X\n",
        "        model.eval() # evaluation dropout 연산시\n",
        "        for i, (data_ , target_) in enumerate(dataloader):\n",
        "\n",
        "            #========================================#\n",
        "            data_, target_ = data_.to(device), target_.to(device)\n",
        "            size += data_.size(0)\n",
        "            pred = model(data_)\n",
        "            _, pred_max = torch.max(pred,1)\n",
        "            loss = criterion(pred, target_)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_correct += ( pred_max == target_ ).type(torch.float).sum().item()\n",
        "\n",
        "            #========================================#\n",
        "\n",
        "    return epoch_correct/size  , epoch_loss / num_baches"
      ],
      "metadata": {
        "id": "itd-dZY-Ul3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "akqQobyJUzi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = 0"
      ],
      "metadata": {
        "id": "l-cUm7U7UzaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "large_vit_model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSWjEXgmXim7",
        "outputId": "0ba2fcde-2333-452c-e48d-7cddb1f4289a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomVitModel(\n",
              "  (base_model): VisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
              "      (norm): Identity()\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (patch_drop): Identity()\n",
              "    (norm_pre): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (4): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (5): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (6): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (7): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (8): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (9): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (10): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (11): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (12): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (13): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (14): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (15): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (16): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (17): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (18): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (19): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (20): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (21): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (22): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (23): Block(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "    (fc_norm): Identity()\n",
              "    (head_drop): Dropout(p=0.0, inplace=False)\n",
              "    (head): Identity()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=256, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter 설정\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.AdamW(large_vit_model.parameters(), lr=0.0001 )\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "EPOCHS = 20 # the number of epochs\n",
        "n_batch = 32 # the number of batches\n"
      ],
      "metadata": {
        "id": "UJVmK7ikEt51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train_acc , train_loss = train(train_loader ,\n",
        "                                   large_vit_model,\n",
        "                                   criterion ,\n",
        "                                   optimizer,\n",
        "                                   lr_scheduler )\n",
        "\n",
        "    val_acc , val_loss = test(val_loader , large_vit_model, criterion)\n",
        "    print(f'epoch:{epoch} \\\n",
        "    train_loss = {train_loss:.4f} , train_acc:{train_acc:.4f} \\\n",
        "    val_loss = {val_loss:.4f} , val_acc:{val_acc:.4f} \\\n",
        "    learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        counter = 0\n",
        "        best_loss = val_loss\n",
        "        torch.save(large_vit_model.state_dict() , \"checkpoints/NN_best.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccC5RiGAUls6",
        "outputId": "4d42ffdd-19fc-4921-dd5c-12fb19c09483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "  5%|▌         | 1/20 [00:14<04:29, 14.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0     train_loss = 0.6846 , train_acc:0.5717     val_loss = 0.6388 , val_acc:0.6350     learning rate: 9e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:27<04:07, 13.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1     train_loss = 0.6628 , train_acc:0.6368     val_loss = 0.6346 , val_acc:0.6350     learning rate: 8.1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:41<03:52, 13.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:2     train_loss = 0.6636 , train_acc:0.6054     val_loss = 0.6337 , val_acc:0.6350     learning rate: 7.290000000000001e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:54<03:37, 13.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:3     train_loss = 0.6657 , train_acc:0.6323     val_loss = 0.6399 , val_acc:0.6350     learning rate: 6.561000000000002e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [01:08<03:23, 13.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:4     train_loss = 0.6597 , train_acc:0.6278     val_loss = 0.6353 , val_acc:0.6350     learning rate: 5.904900000000002e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [01:21<03:09, 13.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:5     train_loss = 0.6589 , train_acc:0.6323     val_loss = 0.6331 , val_acc:0.6350     learning rate: 5.314410000000002e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [01:35<02:55, 13.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:6     train_loss = 0.6560 , train_acc:0.6233     val_loss = 0.6291 , val_acc:0.6350     learning rate: 4.782969000000002e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [01:48<02:42, 13.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:7     train_loss = 0.6534 , train_acc:0.6345     val_loss = 0.6175 , val_acc:0.6350     learning rate: 4.304672100000002e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [02:02<02:28, 13.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:8     train_loss = 0.6474 , train_acc:0.6121     val_loss = 0.6164 , val_acc:0.6350     learning rate: 3.874204890000002e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [02:15<02:15, 13.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:9     train_loss = 0.6692 , train_acc:0.5987     val_loss = 0.6320 , val_acc:0.6350     learning rate: 3.4867844010000016e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [02:29<02:01, 13.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:10     train_loss = 0.6401 , train_acc:0.6300     val_loss = 0.6175 , val_acc:0.6350     learning rate: 3.138105960900002e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [02:42<01:48, 13.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:11     train_loss = 0.6165 , train_acc:0.6368     val_loss = 0.6372 , val_acc:0.6496     learning rate: 2.8242953648100018e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [02:56<01:34, 13.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:12     train_loss = 0.6482 , train_acc:0.6121     val_loss = 0.6145 , val_acc:0.6350     learning rate: 2.5418658283290016e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [03:09<01:21, 13.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:13     train_loss = 0.6381 , train_acc:0.6345     val_loss = 0.6196 , val_acc:0.6350     learning rate: 2.2876792454961016e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [03:23<01:07, 13.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:14     train_loss = 0.6244 , train_acc:0.6300     val_loss = 0.6176 , val_acc:0.6204     learning rate: 2.0589113209464913e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [03:36<00:53, 13.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:15     train_loss = 0.6336 , train_acc:0.6233     val_loss = 0.6104 , val_acc:0.6496     learning rate: 1.8530201888518422e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [03:50<00:40, 13.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:16     train_loss = 0.6303 , train_acc:0.6278     val_loss = 0.6112 , val_acc:0.6350     learning rate: 1.667718169966658e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [04:03<00:26, 13.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:17     train_loss = 0.6258 , train_acc:0.6390     val_loss = 0.6265 , val_acc:0.6569     learning rate: 1.5009463529699922e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [04:17<00:13, 13.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:18     train_loss = 0.6310 , train_acc:0.6166     val_loss = 0.6104 , val_acc:0.6423     learning rate: 1.350851717672993e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [04:30<00:00, 13.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19     train_loss = 0.6279 , train_acc:0.6614     val_loss = 0.6161 , val_acc:0.6642     learning rate: 1.2157665459056937e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc , val_loss = test(test_loader , large_vit_model, criterion)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0TUfJ1MZKTh",
        "outputId": "54e6affa-dd51-4f96-ae8f-c8b57666f4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6826923076923077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zhm27j-ZkGVT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}